{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25a7e5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy\n",
    "numpy.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac28afe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting pickle files that were processed in the previous chapter: text learning\n",
    "words_file = \"../text_learning/your_word_data.pkl\" \n",
    "authors_file = \"../text_learning/your_email_authors.pkl\"\n",
    "word_data = joblib.load( open(words_file, \"rb\"))\n",
    "authors = joblib.load( open(authors_file, \"rb\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3fa7a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### test_size is the percentage of events assigned to the test set (the\n",
    "### remainder go into training)\n",
    "### feature matrices changed to dense representations for compatibility with\n",
    "### classifier functions in versions 0.15.2 and earlier\n",
    "from sklearn.model_selection import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(word_data, authors, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae319eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english')\n",
    "features_train = vectorizer.fit_transform(features_train)\n",
    "features_test  = vectorizer.transform(features_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e0b2156",
   "metadata": {},
   "outputs": [],
   "source": [
    "### a classic way to overfit is to use a small number\n",
    "### of data points and a large number of features;\n",
    "### train on only 150 events to put ourselves in this regime\n",
    "features_train = features_train[:150].toarray()\n",
    "labels_train   = labels_train[:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab1add41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8168373151308305"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(features_train, labels_train)\n",
    "clf.score(features_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0420e8e3",
   "metadata": {},
   "source": [
    "The accuracy score is much higher than expected. If we are overfitting, then the test performance should be relatively low. Since we chose only 150 training points, we would normally expect overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c1407cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. feature no.21323: (0.36363636363636365)\n",
      "2. feature no.18849: (0.1869272434489826)\n",
      "3. feature no.11975: (0.10537857900318125)\n",
      "4. feature no.22546: (0.08406920992286854)\n",
      "5. feature no.29690: (0.047580525890385035)\n",
      "6. feature no.16267: (0.047407407407407405)\n",
      "7. feature no.18095: (0.04266666666666666)\n",
      "8. feature no.13080: (0.026280193236714978)\n",
      "9. feature no.25675: (0.02552933057280883)\n",
      "10. feature no.24320: (0.02481019450033535)\n"
     ]
    }
   ],
   "source": [
    "features_importance_list = clf.feature_importances_\n",
    "import numpy as np\n",
    "indices = np.argsort(features_importance_list)[::-1]\n",
    "for i in range(10):\n",
    "    print (\"{}. feature no.{}: ({})\".format(i+1, indices[i], features_importance_list[indices[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ca678f",
   "metadata": {},
   "source": [
    "An outlier typically has a significance of >0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "608175f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'houectect'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding a word that discriminates the model\n",
    "vectorizer.get_feature_names()[21323]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e27e4ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8168373151308305"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(features_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b1063f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff542a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
